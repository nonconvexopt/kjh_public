{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "if torch.cuda.is_available():\n",
    "    cuda = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    " class DGP(nn.Module):\n",
    "    def __init__(self, dim_in, dim_h, dim_out, num_induce, dim_z):\n",
    "        super(DGP, self).__init__()\n",
    "        self.dim_in = dim_in\n",
    "        self.dim_h = dim_h + [dim_out] #출력층 차원수도 포함\n",
    "        self.dim_out = dim_out\n",
    "        self.num_induce = num_induce\n",
    "        self.dim_z = dim_z\n",
    "        \n",
    "        #커널 하이퍼 파라미터 [layer][dim][Precision/Scaler]\n",
    "        self.ARD_KHP = {}\n",
    "        for ind, width in enumerate(self.dim_h):\n",
    "            self.ARD_KHP[ind] = {}\n",
    "            for dim in range(width):\n",
    "                self.ARD_KHP[ind][dim] = {}\n",
    "                self.ARD_KHP[ind][dim][0] = torch.randn(1, requires_grad=True).cuda() #Precision\n",
    "                self.ARD_KHP[ind][dim][1] = torch.randn(1, requires_grad=True).cuda() #Scaler\n",
    "        \n",
    "        #ARD 파라미터 [layer][dim]\n",
    "        self.ARD_weight = {}\n",
    "        prev_dim = dim_in\n",
    "        for ind, width in enumerate(self.dim_h):\n",
    "            self.ARD_weight[ind] = {}\n",
    "            for dim in range(width):\n",
    "                self.ARD_weight[ind][dim] = torch.ones((prev_dim, 1), requires_grad=True).cuda() #이전 층의 차원 수 만큼의 ARD 파라미터를 가짐.\n",
    "            prev_dim = width\n",
    "        \n",
    "        #Inducing point varational parameter initializing용\n",
    "        self.normal_dist = torch.distributions.MultivariateNormal(torch.zeros(self.num_induce), torch.eye(self.num_induce))\n",
    "        \n",
    "        #q(Z) [dim_z][mean/logvar][num_induce]\n",
    "        self.q_z = {}\n",
    "        for ind in range(self.dim_z):\n",
    "            ind = \"dim \" + str(ind)\n",
    "            self.q_z[ind] = {}\n",
    "            #mean vector\n",
    "            self.q_z[ind][0] = self.normal_dist.sample().squeeze().cuda()\n",
    "            self.q_z[ind][0].require_grad = True\n",
    "            #log var vector for making diagonal cov mat\n",
    "            #assume diagonal cov mat for each z dim\n",
    "            self.q_z[ind][1] = self.normal_dist.sample().squeeze().cuda()\n",
    "            self.q_z[ind][1].require_grad = True\n",
    "        \n",
    "        #q(X) [dim_h][width][mean/logvar][]\n",
    "        self.q_x = {}\n",
    "        for ind, width in enumerate(self.dim_h):\n",
    "            if ind == len(self.dim_h) - 1:\n",
    "                ind = \"out\"\n",
    "            else:\n",
    "                ind = \"hidden \" + str(ind)            \n",
    "            self.q_x[ind] = {}\n",
    "            for dim in range(width):\n",
    "                dim = \"dim \" + str(dim)\n",
    "                #mean vector\n",
    "                self.q_x[ind][dim] = {}\n",
    "                self.q_x[ind][dim][0] = self.normal_dist.sample().squeeze()\n",
    "                self.q_x[ind][dim][0].require_grad = True\n",
    "                #log var vector for making diagonal cov mat\n",
    "                #assume diagonal cov mat for each z dim\n",
    "                self.q_x[ind][dim][1] = self.normal_dist.sample().squeeze()\n",
    "                self.q_x[ind][dim][1].require_grad = True\n",
    "        \n",
    "        \n",
    "        \n",
    "    def update(self):\n",
    "        for ind, weight in enumerate(self.dim_h):\n",
    "            self.inducing_gram[ind] = self.gen_kernel()\n",
    "\n",
    "    def kernel(self, x1, x2, layer):\n",
    "        #ARD squared exponential kernel\n",
    "        res = torch.empty(0, device=cuda)\n",
    "        for dim in range(self.dim_h[layer]):\n",
    "            res = torch.cat((res, self.ARD_KHP * torch.exp(-0.5*self.ARD_weight[layer][dim]*((x1 - x2)**2))))\n",
    "        return res\n",
    "    \n",
    "    def gen_gram(self, X, layer):\n",
    "        with torch.cuda.device(0):\n",
    "            gram = torch.zeros(self.dim_h[layer], X.shape[0], X.shape[0])\n",
    "            for i in range(X.shape[0]):\n",
    "                for j in range(i + 1, X.shape[0]):\n",
    "                    gram[:, i, j] = self.kernel(X[i,:], X[j,:], layer)\n",
    "            gram += gram.transpose(1, 2)\n",
    "        return gram\n",
    "\"\"\"  \n",
    "    def predict\n",
    "\n",
    "    def loss(self, pred, true):\n",
    "        #논문에 적힌 Variational Lower Bound 구현\n",
    "        g_Y = \n",
    "        r_X = \n",
    "        ent_q = torch.zero(1)\n",
    "        for layer, width in enumerate(dim_h):\n",
    "            ent_q += 0.5 * (width * (1 + torch.log(2 * np.pi)) + torch.log(torch.det()))\n",
    "        KLD = torch.sum(self.q_z_var + (self.q_z_mean ** 2) - torch.log(self.q_z_var) - 1)\n",
    "        return g_Y + r_X + ent_q - KLD\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return \n",
    "\"\"\"\n",
    "model = DGP(3, [5, 4], 3, 10, 10).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hidden 0': {'dim 0': {0: tensor([ 1.7544, -0.9738,  2.2291,  1.6986, -0.3788,  0.5093,  1.5721,  0.7334,\n",
       "           -0.0913,  0.7867]),\n",
       "   1: tensor([ 0.2453,  0.5409,  1.2960, -1.0988, -1.6336, -0.2094, -0.8414,  1.5037,\n",
       "            1.0400,  0.2447])},\n",
       "  'dim 1': {0: tensor([ 0.0023, -0.1311, -1.1004, -0.4292, -0.9047,  0.9575,  1.0021,  0.3088,\n",
       "           -0.8963, -0.8142]),\n",
       "   1: tensor([ 0.9734,  0.6366, -0.3404, -0.9988, -0.3845,  0.5376,  2.5069,  0.1145,\n",
       "            0.5485,  1.8045])},\n",
       "  'dim 2': {0: tensor([ 0.6291,  1.1244,  1.6941, -0.8975, -0.2336,  0.5612, -0.0400, -0.1889,\n",
       "           -0.7147, -0.0330]),\n",
       "   1: tensor([-1.4685,  1.1591, -0.9319,  1.4161,  0.1267, -0.6124,  1.0211,  1.0955,\n",
       "           -0.4380, -0.5487])},\n",
       "  'dim 3': {0: tensor([ 0.8054,  0.5660, -1.0774,  0.3816,  0.2961,  2.2559, -0.7331, -0.1979,\n",
       "           -1.1274,  0.9697]),\n",
       "   1: tensor([-0.4184,  0.8969,  0.9777, -1.5054,  0.5407,  1.2159, -0.7630, -1.0303,\n",
       "            1.0611,  1.0992])},\n",
       "  'dim 4': {0: tensor([ 0.4219, -2.0098,  1.4900,  2.3167, -0.2386,  0.7427,  0.6665, -0.1589,\n",
       "           -0.9416,  0.1248]),\n",
       "   1: tensor([-0.7403,  1.0854,  1.1671, -1.5339, -1.1481, -0.8336,  0.0882, -0.3256,\n",
       "           -0.4745, -0.2256])}},\n",
       " 'hidden 1': {'dim 0': {0: tensor([ 1.0158,  1.5174,  0.2250, -0.6624,  0.1235, -1.7916, -1.1035, -0.4903,\n",
       "            0.5207, -1.0777]),\n",
       "   1: tensor([-0.4037,  0.0369, -0.3086,  1.0689, -0.9489, -0.0797,  1.2667,  1.1434,\n",
       "           -0.0939,  1.6617])},\n",
       "  'dim 1': {0: tensor([-0.9347, -0.0854,  2.0268, -1.0854, -0.8841, -3.3138,  0.4236,  1.5208,\n",
       "            0.2411,  1.5477]),\n",
       "   1: tensor([ 0.9214, -0.3165,  1.5636, -1.2459,  0.1202, -1.0087, -0.1481,  0.7942,\n",
       "            0.5734, -0.3477])},\n",
       "  'dim 2': {0: tensor([ 1.1118, -0.2247,  0.0706, -0.1664, -0.6488, -0.4938,  0.6108,  1.7863,\n",
       "            0.2350,  0.4893]),\n",
       "   1: tensor([ 0.6731, -1.5711, -0.5982, -0.4620, -0.8457,  0.0775, -0.8264,  1.0041,\n",
       "            1.7126, -1.7508])},\n",
       "  'dim 3': {0: tensor([-1.3447, -0.2988,  0.8567,  0.1857,  0.4436,  0.2474,  1.6921,  1.8705,\n",
       "            0.9584,  1.5373]),\n",
       "   1: tensor([-0.0435,  1.0062,  0.5831, -0.5770, -1.2052,  1.6978, -1.5064, -0.2006,\n",
       "           -1.7927, -0.8990])}},\n",
       " 'out': {'dim 0': {0: tensor([ 1.4361, -1.4619,  1.1267, -0.5415,  2.1357,  0.8765, -1.1678, -1.1566,\n",
       "            1.2975, -0.6379]),\n",
       "   1: tensor([ 1.1657, -0.4919, -0.6997,  1.3157,  0.5716,  1.9760,  0.8741, -0.0356,\n",
       "           -0.2973,  1.7674])},\n",
       "  'dim 1': {0: tensor([ 1.6911,  0.0573,  1.3156,  0.7429,  0.9342,  0.2137,  0.6552, -0.2011,\n",
       "           -1.3397,  0.5156]),\n",
       "   1: tensor([-0.2298,  0.4849,  0.5084,  1.0877,  1.2829, -0.1614,  0.4346, -2.0475,\n",
       "            0.6617,  0.7908])},\n",
       "  'dim 2': {0: tensor([-2.0985,  0.3475,  3.3615,  0.2394,  1.4244,  1.3747,  0.4701, -0.8898,\n",
       "           -0.4528, -0.2379]),\n",
       "   1: tensor([-1.2823, -0.0302, -0.6839, -0.9605,  0.2977, -0.0887,  0.8225,  0.4315,\n",
       "            0.3875,  0.2500])}}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.q_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "mul() received an invalid combination of arguments - got (dict), but expected one of:\n * (Tensor other)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mdict\u001b[0m)\n * (Number other)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mdict\u001b[0m)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-1bd3341cfcf3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen_gram\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-3-b2eabe71aa26>\u001b[0m in \u001b[0;36mgen_gram\u001b[1;34m(self, X, layer)\u001b[0m\n\u001b[0;32m     79\u001b[0m            \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m                \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m                    \u001b[0mgram\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m            \u001b[0mgram\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mgram\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[0mgram\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-b2eabe71aa26>\u001b[0m in \u001b[0;36mkernel\u001b[1;34m(self, x1, x2, layer)\u001b[0m\n\u001b[0;32m     71\u001b[0m        \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m        \u001b[1;32mfor\u001b[0m \u001b[0mdim\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim_h\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m            \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mARD_KHP\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mARD_weight\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mx2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: mul() received an invalid combination of arguments - got (dict), but expected one of:\n * (Tensor other)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mdict\u001b[0m)\n * (Number other)\n      didn't match because some of the arguments have invalid types: (\u001b[31;1mdict\u001b[0m)\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(3, 3).cuda()\n",
    "model.gen_gram(a, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.])\n",
      "tensor([ 0.2573,  1.5947, -0.2132,  0.6438, -1.7222], requires_grad=True)\n",
      "tensor([1.])\n",
      "tensor([1., 1., 1., 1., 1.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(1).detach()\n",
    "b = torch.randn(5, requires_grad=True)\n",
    "print(x)\n",
    "print(b)\n",
    "\n",
    "y = x - b\n",
    "loss = torch.sum(y**2)\n",
    "loss.backward()\n",
    "\n",
    "optimizer = optim.SGD([b], 0.5)\n",
    "optimizer.step()\n",
    "print(x)\n",
    "print(b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cat(torch,)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
