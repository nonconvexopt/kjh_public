{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "import torch.utils as utils\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as TF\n",
    "import torchvision.datasets as dsets\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torchvision import models\n",
    "\n",
    "import cv2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "os.chdir(\"/projects/2019연구학점제/\")\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "import time\n",
    "import copy\n",
    "import random as rd\n",
    "\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_train = 256\n",
    "batch_size_test = 256\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('..data/MNIST/', train=True, download=False,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('/MNIST/', train=False, download=False,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])), batch_size=batch_size_test, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "examples = enumerate(test_loader)\n",
    "batch_idx, (example_data, example_targets) = next(examples)\n",
    "\n",
    "fig = plt.figure()\n",
    "for i in range(6):\n",
    "    plt.subplot(2,3,i+1)\n",
    "    plt.tight_layout()\n",
    "    plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
    "    plt.title(\"Ground Truth: {}\".format(example_targets[i]))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class flatten(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(flatten, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        shape = torch.prod(torch.tensor(x.shape[1:])).item()\n",
    "        return x.view(-1, shape)\n",
    "\n",
    "class sampler_net(nn.Module):\n",
    "    def __init__(self, num_params):\n",
    "        super(sampler_net, self).__init__()\n",
    "        self.kernel_size = (3, 3)\n",
    "        self.num_params = num_params\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.BatchNorm2d(1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(1, 4, kernel_size = self.kernel_size, padding = tuple(x//2 for x in self.kernel_size), stride = (2, 2)),\n",
    "            nn.MaxPool2d((2,2)),\n",
    "            \n",
    "            nn.BatchNorm2d(4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(4, 8, kernel_size = self.kernel_size, padding = tuple(x//2 for x in self.kernel_size), stride = (2, 2)),\n",
    "            nn.MaxPool2d((2,2)),\n",
    "\n",
    "            flatten()\n",
    "        )\n",
    "        \n",
    "        self.mean = nn.Sequential(\n",
    "            \n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, self.num_params),\n",
    "        )\n",
    "        \n",
    "        self.var = nn.Sequential(\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, self.num_params),\n",
    "            \n",
    "            nn.Softplus()\n",
    "        )\n",
    "\n",
    "        self.sample_dist = torch.distributions.MultivariateNormal(torch.zeros(self.num_params), torch.eye(self.num_params))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        return self.mean(x) + (self.sample_dist.sample().cuda() * self.var(x))\n",
    "\n",
    "    \n",
    "class sample_net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(sample_net, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv2d(1, 4, kernel_size = (3, 3), padding = (1, 1), stride = (2,2)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((2,2)),\n",
    "            \n",
    "            nn.Conv2d(4, 8, kernel_size = (3, 3), padding = (1, 1), stride = (2,2)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d((2,2)),\n",
    "            \n",
    "            flatten(),\n",
    "            \n",
    "            nn.Linear(2 * 2 * 8, 10, bias = True),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.layers(x).unsqueeze(0)\n",
    "    \n",
    "    def set_params(self, params):\n",
    "        param_count = 0\n",
    "        self.layers[0].weight = torch.nn.Parameter(params[param_count:param_count + self.layers[0].weight.numel()].view(self.layers[0].weight.size()))\n",
    "        param_count += self.layers[0].weight.numel()\n",
    "        self.layers[0].bias = torch.nn.Parameter(params[param_count:param_count + self.layers[0].bias.numel()].view(self.layers[0].bias.size()))\n",
    "        param_count += self.layers[0].bias.numel()\n",
    "        self.layers[3].weight = torch.nn.Parameter(params[param_count:param_count + self.layers[3].weight.numel()].view(self.layers[3].weight.size()))\n",
    "        param_count += self.layers[3].weight.numel()\n",
    "        self.layers[3].bias = torch.nn.Parameter(params[param_count:param_count + self.layers[3].bias.numel()].view(self.layers[3].bias.size()))\n",
    "        param_count += self.layers[3].bias.numel()\n",
    "        self.layers[7].weight = torch.nn.Parameter(params[param_count:param_count + self.layers[7].weight.numel()].view(self.layers[7].weight.size()))\n",
    "        param_count += self.layers[7].weight.numel()\n",
    "        self.layers[7].bias = torch.nn.Parameter(params[param_count:param_count + self.layers[7].bias.numel()].view(self.layers[7].bias.size()))\n",
    "        param_count += self.layers[7].bias.numel()\n",
    "    \n",
    "    def fit(self, x, params):\n",
    "        for ind in range(params.shape[0]):\n",
    "            self.set_params(params[ind])\n",
    "            if ind:\n",
    "                output= torch.cat((output, self.forward(x)))\n",
    "            else:\n",
    "                output = self.forward(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[36, 4, 288, 8, 320, 10]\n",
      "666\n",
      "[1, 1, 36, 4, 4, 4, 288, 8, 32, 32, 21312, 666, 32, 32, 21312, 666]\n",
      "44430\n",
      "CPU times: user 143 ms, sys: 40.3 ms, total: 183 ms\n",
      "Wall time: 360 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sample = sample_net().cuda()\n",
    "print([p.numel() for p in sample.parameters() if p.requires_grad])\n",
    "print(sum(p.numel() for p in sample.parameters() if p.requires_grad))\n",
    "\n",
    "sampler = sampler_net(sum(p.numel() for p in sample.parameters() if p.requires_grad)).cuda()\n",
    "print([p.numel() for p in sampler.parameters() if p.requires_grad])\n",
    "print(sum(p.numel() for p in sampler.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 666])\n",
      "torch.Size([256, 256, 10])\n",
      "CPU times: user 457 ms, sys: 0 ns, total: 457 ms\n",
      "Wall time: 602 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(sampler(example_data.cuda()).shape)\n",
    "print(sample.fit(example_data.cuda(), sampler(example_data.cuda())).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Training</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 1000\n",
    "lr = 3e-4\n",
    "optimizer_sample = torch.optim.Adam(sample.parameters(), lr = lr)\n",
    "optimizer_sampler = torch.optim.Adam(sampler.parameters(), lr = lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = sample_net().cuda()\n",
    "sampler = sampler_net(sum(p.numel() for p in sample.parameters() if p.requires_grad)).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "CE_loss = nn.CrossEntropyLoss()\n",
    "def multi_crit(output, label):\n",
    "    loss = 0.0\n",
    "    for dim in range(output.shape[0]):\n",
    "        loss += CE_loss(output[dim], label)\n",
    "    return loss\n",
    "criterion = multi_crit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 0, test loss = 299.38000, time: 123.176095 sec\n",
      "epoch : 1, test loss = 318.00900, time: 123.208699 sec\n",
      "epoch : 2, test loss = 302.55817, time: 123.238706 sec\n",
      "epoch : 3, test loss = 295.77338, time: 123.376549 sec\n",
      "epoch : 4, test loss = 308.97491, time: 123.362425 sec\n",
      "epoch : 5, test loss = 339.54861, time: 123.338022 sec\n",
      "epoch : 6, test loss = 308.51120, time: 123.297865 sec\n",
      "epoch : 7, test loss = 270.11276, time: 123.262603 sec\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-037e8e1758f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulti_crit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0moptimizer_sampler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    105\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \"\"\"\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for run in range(epoch):\n",
    "    start = time.time()\n",
    "    \n",
    "    #Training\n",
    "    sampler.train()\n",
    "    sample.train()\n",
    "    for ind, data in enumerate(train_loader):\n",
    "        optimizer_sampler.zero_grad()\n",
    "        img, label = data\n",
    "        output = sample.fit(img.cuda(), sampler(img.cuda()))\n",
    "        loss = multi_crit(output, label.cuda())\n",
    "        loss.backward()\n",
    "        optimizer_sampler.step()\n",
    "    \n",
    "    #Test\n",
    "    sampler.eval()\n",
    "    sample.eval()\n",
    "    with torch.no_grad():\n",
    "        test_loss = 0.0\n",
    "        for ind, data in enumerate(test_loader):\n",
    "            img, label = data\n",
    "            output = sample.fit(img.cuda(), sampler(img.cuda()))\n",
    "            test_loss += multi_crit(output, label.cuda())\n",
    "        test_loss /= (len(test_loader) * 64)\n",
    "    print(\"epoch : %d, test loss = %5.5f, time: %f sec\" %(run, test_loss, time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
