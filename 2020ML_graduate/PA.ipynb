{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as nprd\n",
    "import pandas as pd\n",
    "import os\n",
    "import sklearn\n",
    "from sklearn import svm, tree\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "import torch.utils as utils\n",
    "import torch.utils.data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "device = torch.device('cuda')\n",
    "\n",
    "import math\n",
    "import time\n",
    "import copy\n",
    "import random as rd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./ionosphere.data\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nprd.seed(2020)\n",
    "data = pd.read_csv(\"./ionosphere.data\", header=None)\n",
    "data = data.loc[nprd.permutation(len(data)),:]\n",
    "num_data = len(data)\n",
    "split_size = num_data // 10\n",
    "data_split = []\n",
    "for split_ind in range(9):\n",
    "    data_split.append(data[split_ind * split_size:(split_ind+1) * split_size])\n",
    "data_split.append(data[(split_ind+1) * split_size:])\n",
    "\n",
    "cv_data = []\n",
    "test_labels = data.loc[:, data.columns[-1]]\n",
    "for split_ind in range(10):\n",
    "    split_train = pd.DataFrame()\n",
    "    for ind in range(10):\n",
    "        if ind != split_ind:\n",
    "            split_train = split_train.append(data_split[ind], ignore_index=True)\n",
    "    cv_data.append([split_train, data_split[split_ind]])\n",
    "    \n",
    "class_prop = {'g':sum(data.loc[:,data.columns[-1]] == 'g'),\n",
    "              'b':sum(data.loc[:,data.columns[-1]] == 'b')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model):\n",
    "    for ind in range(10):\n",
    "        train_data, test_data = cv_data[ind]\n",
    "        train_X = train_data.loc[:, data.columns[:-1]]\n",
    "        test_X = test_data.loc[:, data.columns[:-1]]\n",
    "        train_X = StandardScaler().fit(train_X).transform(train_X)\n",
    "        test_X = StandardScaler().fit(test_X).transform(test_X)\n",
    "        train_Y = train_data.loc[:, data.columns[-1]]\n",
    "        model.fit(train_X, train_Y)\n",
    "\n",
    "        if ind:\n",
    "            predicts = np.concatenate((predicts, model.predict(test_X)), axis = 0)\n",
    "        else:\n",
    "            predicts = model.predict(test_X)\n",
    "\n",
    "    print(accuracy_score(test_labels, predicts))\n",
    "    print(precision_recall_fscore_support(test_labels, predicts, average='binary', pos_label='g'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9344729344729344\n",
      "(0.9243697478991597, 0.9777777777777777, 0.9503239740820735, None)\n"
     ]
    }
   ],
   "source": [
    "test(svm.SVC(C=0.05, kernel='rbf', class_weight=class_prop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8660968660968661\n",
      "(0.8677685950413223, 0.9333333333333333, 0.899357601713062, None)\n"
     ]
    }
   ],
   "source": [
    "test(tree.DecisionTreeClassifier(criterion = 'entropy', class_weight=class_prop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9116809116809117\n",
      "(0.9181034482758621, 0.9466666666666667, 0.9321663019693653, None)\n"
     ]
    }
   ],
   "source": [
    "test(RandomForestClassifier(class_weight=class_prop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8774928774928775\n",
      "(0.8760330578512396, 0.9422222222222222, 0.9079229122055673, None)\n"
     ]
    }
   ],
   "source": [
    "test(AdaBoostClassifier(base_estimator=tree.DecisionTreeClassifier(max_depth=1), n_estimators = 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear_flipout(nn.Module):\n",
    "    def __init__(self, in_features, out_features, bias=True, device = \"cuda\"):\n",
    "        super(Linear_flipout, self).__init__()\n",
    "        \n",
    "        self.device = device\n",
    "        \n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        \n",
    "        self.weight_mu = nn.Parameter(torch.empty([self.in_features, self.out_features], device = device).double().normal_(0, 1/self.out_features))\n",
    "        self.weight_logvar = nn.Parameter(torch.ones([self.in_features, self.out_features], device = device).double() *\n",
    "                                          (- torch.empty(1, device = device).fill_(self.out_features).log()))\n",
    "        \n",
    "        self.bias_mu = nn.Parameter(torch.zeros(self.out_features, device = device).double())\n",
    "        self.bias_logvar = nn.Parameter(torch.ones(self.out_features, device = device).double() *\n",
    "                                            (- torch.empty(1, device = device).fill_(self.out_features).log()))\n",
    "\n",
    "            \n",
    "    def forward(self, x):\n",
    "        weight_noise = torch.empty(self.weight_mu.shape, requires_grad = False, device = device).normal_(0,1)\n",
    "        bias_noise = torch.empty(self.bias_mu.shape, requires_grad = False, device = device).normal_(0,1)\n",
    "        in_sign = torch.empty(x.shape, requires_grad = False, device = device).uniform_(-1,1).sign()\n",
    "        out_sign = torch.empty([x.shape[0], self.out_features], requires_grad = False, device = device).uniform_(-1,1).sign()\n",
    "\n",
    "        x = torch.mm(x, self.weight_mu) + torch.mm(in_sign * x, weight_noise * self.weight_mu * self.weight_logvar.div(2).exp()) * out_sign\n",
    "        x += (1 + bias_noise * self.bias_logvar.div(2).exp()) * self.bias_mu\n",
    "\n",
    "        kld = (self.weight_mu.pow(2) - self.weight_logvar + self.weight_logvar.exp() - 1).mean()/2\n",
    "        kld += (self.bias_mu.pow(2) - self.bias_logvar + self.bias_logvar.exp() - 1).mean()/2\n",
    "        \n",
    "        return x, kld\n",
    "    \n",
    "class bnn(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(bnn, self).__init__()\n",
    "        self.l1 = Linear_flipout(34, 200)\n",
    "        self.a1 = nn.ELU()\n",
    "        \n",
    "        self.l2 = Linear_flipout(200, 200)\n",
    "        self.a2 = nn.ELU()\n",
    "        \n",
    "        self.l3 = Linear_flipout(200, 2)\n",
    "        self.a3 = nn.ELU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.from_numpy(x).cuda().double()\n",
    "        \n",
    "        x, kld1 = self.l1(x)\n",
    "        x = self.a1(x)\n",
    "        \n",
    "        x, kld2 = self.l2(x)\n",
    "        x = self.a2(x)\n",
    "        \n",
    "        x, kld3 = self.l3(x)\n",
    "        x = self.a3(x)\n",
    "        \n",
    "        return x, kld1 + kld2 + kld3\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        loss = LabelSmoothingLoss(classes = 2, smoothing = 0.1)\n",
    "        optimizer = optim.SGD(self.parameters(), lr = 1e-3, momentum= 0.9)\n",
    "        for epoch in range(200):\n",
    "            optimizer.zero_grad()\n",
    "            pred, kld = self.forward(x)\n",
    "            loss(pred, torch.from_numpy((y == 'g').values).long().cuda()).backward()\n",
    "            optimizer.step()\n",
    "        optimizer = optim.SGD(self.parameters(), lr = 1e-4, momentum = 0.9)\n",
    "        for epoch in range(200):\n",
    "            optimizer.zero_grad()\n",
    "            pred, kld = self.forward(x)\n",
    "            loss(pred, torch.from_numpy((y == 'g').values).long().cuda()).backward()\n",
    "            optimizer.step()\n",
    "        optimizer = optim.SGD(self.parameters(), lr = 1e-5, momentum = 0.9)\n",
    "        for epoch in range(200):\n",
    "            optimizer.zero_grad()\n",
    "            pred, kld = self.forward(x)\n",
    "            loss(pred, torch.from_numpy((y == 'g').values).long().cuda()).backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "    def predict(self, x):\n",
    "        with torch.no_grad():\n",
    "            pred = self.forward(x)[0]\n",
    "            res = pd.Series('b').repeat(pred.shape[0])\n",
    "            res.loc[pred[:,1].cpu().numpy() >= class_prop['g']/(class_prop['g']+class_prop['b'])] = 'g'            \n",
    "            return res\n",
    "\n",
    "class LabelSmoothingLoss(nn.Module):\n",
    "    def __init__(self, classes, smoothing=0.0, dim=-1):\n",
    "        super(LabelSmoothingLoss, self).__init__()\n",
    "        self.confidence = 1.0 - smoothing\n",
    "        self.smoothing = smoothing\n",
    "        self.cls = classes\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        pred = pred.log_softmax(dim=self.dim)\n",
    "        true_dist = torch.zeros_like(pred)\n",
    "        true_dist.fill_(self.smoothing / (self.cls - 1))\n",
    "        true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n",
    "        \n",
    "        return torch.mean(torch.sum(-true_dist * pred, dim=self.dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8888888888888888\n",
      "(0.9043478260869565, 0.9244444444444444, 0.9142857142857144, None)\n"
     ]
    }
   ],
   "source": [
    "test(bnn().cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
